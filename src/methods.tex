\section{Image Processing Methods}

All MRI volumes will be processed using Advanced Normalization Tools
(ANTs) \href{http://www.picsl.upenn.edu/ANTS}{(click here for
link)}\cite{Avants2011a,Avants2011,Murphy2011,Tustison2010,Tustison2011,Tustison2011a}
via previously reported procedures validated as highly accurate
\cite{Klein2009,Klein2010,Murphy2011,Avants2011}.  In general, ANTs-based
processing for multiple modalities is based on, first, defining a
template to guide the population normalization and segmentation
procedures \cite{Avants2011a,Avants2011}.  Traditionally, this
approach was used for single modalities but, more recently, is
exetended for multiple modalities via multiple-modality cohort-specific templates
that capture the average shape and appearance of T1, DTI and
functional images, as in \cite{Kim2010,Avants2011a,Jain2012,Tustison2012}.  We use the
template to guide brain extraction for all modalities and subsequent
tissue or neuroanatomical parcellation \cite{Avants2011a}.  
This general procedure allows several complementary measurements to be
extracted from neuroimaging including 
cortical thickness via DiReCT \cite{Das2009a}, mean diffusion which
may be sensitive to neuronal death \cite{}, fractional anisotropy,
cerebral blood flow from ASL \cite{Jain2012} or graph connectivity metrics from ASL or
BOLD \cite{}.  These measurements, taken together, yield a
multispectral picture of brain health or disease that may have
significant translational value for diagnostics \cite{McMillan2013a} and prognostics \cite{Yuh2013}.

Justification for each modality is described briefly: 

\noindent{\em Jacobian-based Volume from T1-weighted MRI:}  T1 MRI is
typically the highest resolution anatomical image routinely collected
in both clinical and research MRI protocols.  Image registration
methods are able to use T1 MRI to obtain voxel-wise measurement of the
subject structural volume relative to a group local template or
relative to a baseline timepoint.  These measurements are used in
Tensor-Based Morphometry (TBM) which, when performed symmetrically as
in my prior work \cite{Yushkevich2010a,Das2012}, is highly accurate
and provides detailed information on shape change over time
\cite{Brambati2007,Hua2011,Kim2013} or across a population \cite{Kim2008,Massimo2009,Morgan2011,Hanson2010,Hanson2012}.

\noindent{\em Cortical thickness from T1-weighted MRI:}  A measurement that is both sensitive and specific in neurodegeneration \cite{Stricker2012,Libon2012,McMillan2013} and which is associated with cognitive decline \cite{Dickerson2011,Avants2010}.  

\noindent{\em Fractional anisotropy (FA) from DTI:}  A measurement of white matter integrity that may reveal the connectivity components of neurodegeneration \cite{Zhang2009}, potentially captures a different aspect of the disease process \cite{Englund2004} and may differentiate tau and TDP-43 effects \cite{McMillan2013b}.    

\noindent{\em BOLD Network Analysis:} BOLD-based network analysis
\cite{Spoormaker2010,Sanz-Arigita2010} has emerged as a powerful tool
with specific value in both brain injury
\cite{Mayer2011,Scheibel2012,Zhou2013}, the study of intervention
strategies \cite{Roy2010,FeldsteinEwing2011} and measurement of pain
\cite{Mayhew2013}.

\noindent{\em Cerebral blood flow (CBF) from ASL:}  This functional
quantitative measure (versus the relative values provided by BOLD) has
the potential to reveal alterations in the brain due to injury
\cite{Kim2008}, pain \cite{Howard2011}, pharmacological intervention \cite{Black2010,Jenkins2012} or that precede visible structural change and may
indicate cortical reorganization \cite{Hayward2010}.  ASL-based CBF
also accurately recapitulates PET imaging in Alzheimer's disease \cite{Chen2011,Mak2012}.
CBF is a more repeatable functional measurement than BOLD
\cite{Liu2007,Aguirre2012}, may be used in network analysis in lieu of
or combination with 
BOLD \cite{Duda2013} and provides a unique view on the brain complementary to DTI and T1.  

We now detail both general processing strategies and those that are
specific to each modality.

\subsection{ANTs volumetric-based cortical thickness estimation pipeline}

The ANTs-based cortical thickness estimation workflow is illustrated 
in Figure \ref{fig:pipeline}.  The steps are as follows:
\begin{enumerate}
  \item initial N4 bias correction on input anatomical MRI,
  \item brain extraction using a hybrid segmentation/template-based strategy,
  \item alternation between prior-based segmentation and white matter posterior
        probability weighted bias correction,
  \item DiReCT-based cortical thickness estimation, and
  \item optional normalization to specified template.
\end{enumerate}
Each component, including both software and data, is briefly detailed 
below with the relevant references for additional information. 
\begin{figure*}
  \centering
  \includegraphics[width=170mm]{figs/Kapowski_pipeline2.pdf}
  \caption{Illustration of the main components of the ANTs processing 
  workflow containing all elements for determining cortical thickness. 
  Not shown is the optional subject to template registration.}
  \label{fig:pipeline}
\end{figure*}

\subsubsection{Anatomical template construction}
Normalizing images to a standard coordinate system
reduces intersubject variability in population studies.  Various
approaches exist for determining the normalized space such as the selection
of a pre-existing template based on a single subject, e.g. the Talairach
atlas \citep{Talairach1988}, or a publicly available averaged group of
subjects, e.g. the MNI \citep{Collins1994} or ICBM \citep{Mazziotta1995}
templates.  Additionally, mean templates constructed from labeled
data can be used to construct spatial priors for improving segmentation
algorithms.
The work of \cite{avants2010} explicitly models the geometric component of the 
normalized space during optimization to produce such mean templates.  Coupling the intrinsic symmetry of 
SyN pairwise registration \citep{Avants2011} and an
optimized shape-based sharpening/averaging of the template appearance, Symmetric Group
Normalization (SyGN) is a powerful framework for producing optimal population-specific
templates \citep{avants2010}.

\subsubsection{N4 Bias field correction}

Critical to quantitative processing of MRI is the minimization of
field inhomogeneity effects which causes artificial low frequency 
intensity variation across the image.  Large-scale studies, such
as the Alzheimer's Disease Neuroimaging Initiative (ADNI), employ
perhaps the most widely used bias correction algorithm, N3 \cite{sled1998}, 
as part of their standard protocol \citep{boyes2008}.

In \cite{Tustison2010}, we introduced an improvement of N3, denoted as
``N4'', which demonstrates a significant increase in performance and convergence behavior
on a variety of data.  This improvement is a result of an enhanced 
fitting routine (which includes multi-resolution capabilities) and a modified optimization 
formulation.  For our workflow, the additional possibility of specifying
a weighted mask in N4 permits the use of a ``pure tissue'' probability map 
(described below)
calculated during the segmentation pipeline for further improvement of 
bias field estimation.  In addition to its public availability 
through ANTs and the Insight Toolkit, it has also been included in
the popular open source Slicer software package for visualization and medical
image computing \cite{fedorov2011}.

N4 is used in two places during the individual subject processing (cf. Figure
\ref{fig:pipeline}).  Following conversion of the raw dicom T1-weighted image
to Nifti format using our related \verb#Neuropipedream# set of raw image conversion
and organization tools%
\footnote{
http://sourceforge.net/projects/neuropipedream/
}, N4 is used to generate an initial bias corrected image for use in
brain extraction.  The input mask is created by adaptively thresholding 
the background from the foreground using Otsu's algorithm \cite{otsu1979}.
Following brain extraction, three-tissue segmentation involves iterating
between bias field correction using the current pure tissue 
probability map as a weight mask and then using that bias corrected image
as input to the Atropos segmentation step (described in the next section). 

\subsubsection{Atropos 3-tissue segmentation}

In \cite{Avants2011a} we presented an open source $n$-tissue segmentation software tool
(which we denote as ``Atropos'') attempting to distill 20+ years of active research in this area
particularly some of its most seminal work (e.g. \cite{zhang2001,ashburner2005}). 
Specification of prior probabilities includes spatially varying Markov Random Field modeling, 
prior label maps, and prior probability maps typically derived from our template building 
process.  Additional
capabilities include handling of multivariate data, 
partial volume modeling \cite{shattuck2001}, a memory-minimization mode,
label propagation, a plug-n-play architecture for incorporation of novel likelihood models
which includes both parametric and non-parametric models for both scalar and tensorial
images, and alternative posterior formulations for different segmentation tasks.

Due to the important interplay between segmentation and bias correction,
we perform multiple N4 $\Leftrightarrow$ Atropos iterations.
In order to better integrate Atropos and N4, we use  
a pure tissue probability weight mask generated from the 
posterior probabilities generated from the segmentation 
process.  Given $N$ labels and the corresponding $N$
posterior probability maps $\{ P_1, \ldots, P_N\}$ produced
during the segmentation process, the N4 weight mask is 
created at each N4 $\Leftrightarrow$ Atropos iteration from
\begin{align}
  P_{pure\,\,tissue}(\mathbf{x}) = \sum_{i=1}^N P_i(\mathbf{x}) \prod_{j=1, j \neq i}^N \left( 1 - P_j(\mathbf{x}) \right).
\end{align}
One of the key insights of the original N3 algorithm is the
observation that inhomogeneities cause the intensity values of
pure tissue peaks to spread in the intensity histogram as though
convolved with a Gaussian.  A core contribution of N3 is the
proposed corrective of deconvolving the intensity histogram to 
accentuate the tissue peaks coupled with a spatial smoothing 
constraint. The pure tissue probability mask
weights more heavily the voxels corresponding to pure tissue 
types (as determined by the segmentation) during the deconvolution process 
while minimizing the contribution of regions such as the gray/white matter 
interface where peak membership is ambiguous. 

\subsubsection{Brain extraction}

Brain extraction using ANTs combines template building, high-performance
brain image registration \citep{Avants2011}, and Atropos with topological refinements.  
An optimal template for brain extraction is 
generated offline using labeled brain data.  For example, in this work we use the LPBA40 data 
for generating a brain extraction template and a corresponding brain probability mask which is
available on the website associated with this submission. 

  The warped template probability map is thresholded at 0.5 and the resulting mask is dilated
with a radius of 2.  Atropos is used to generate an initial 3-tissue segmentation estimate within the mask
region.  Each of the three tissue masks undergo specific morphological operations which are then
combined to create a brain extraction mask for use in the rest of the
cortical thickness workflow. 

A comparison using open access brain data with publicly available
brain extraction algorithms including AFNI's \verb#3dIntracranial#
\citep{ward1999}, FSL's \verb#BET2# \citep{smith2002}, Freesurfer's
\verb#mri_watershed# \citep{segonne2004}, and BrainSuite
\citep{dogdas2005} demonstrated that our combined
registration/segmentation approach \citep{avants2010a} performs at the
top level alongside BrainSuite (tuned) and FreeSurfer.


\subsubsection{DiReCT (aka KellySlater/KellyKapowski) Cortical Thickness Estimation}

DiReCT was introduced 
in \cite{das2009} and made available in ANTs with the program \verb#KellySlater#.
Since then several improvements have been made and incorporated into the program
\verb#KellyKapowski#.%
Among the most significant advancements is that the more recent
implementation is multi-threaded, written in rigorous ITK coding style, and 
has been made publicly available through  ANTs complete with a unique user 
interface design developed specifically for ANTs tools.  


\subsubsection{DTI Processing with ANTs} 

%Phil --- see
%\href{www.ncbi.nlm.nih.gov/pubmed/23151955‎}{www.ncbi.nlm.nih.gov/pubmed/23151955}
% for content.
Diffusion MRI data consists of a series of images, one or more unweighted images (with no diffusion weighting) and multiple diffusion-weighted images (DWI) sensitized to diffusion along unique directions. The data from all of the images is used to fit a Gaussian model of diffusion in three dimensions, parameterized by the diffusion tensor (DT). The DT encodes complimentary information on the scale, anisotropy, and orientation of apparent diffusion in each voxel, which are sensitive to different aspects of the tissue microstructure, particularly white matter integrity and the local alignment of axon fiber bundles, which we can use to study global white matter connectivity. 

Because of the relatively long imaging time and use of strong gradients, diffusion data is particularly sensitive to misalignment caused by distortion and subject motion. Co-registration of the image volumes is challenging because of limited spatial resolution and highly variable signal to noise ratio in the DWI. After pre-processing and diffusion tensor calculation, we must spatially normalize the diffusion tensors to template space for analysis. We accomplish this by first aligning the diffusion image with the subject's high-resolution T1-weighted image, correcting for any head motion and distortion introduced by differences in the MRI protocols between the T1-weighted image and the DWI. We then combine this intra-subject transformation with the transformation mapping the T1-weighted image to the template space. 

We have developed an automated processing pipeline for diffusion imaging using the open source tools Camino \cite{Cook2006ISMRM} and ANTs, which provides pre-processing, brain extraction, diffusion tensor computation, and normalization to template space, as well as diagnostic images in the subject space to aid quality control, including fractional anisotropy, average corrected DWI, and noise variance.

The first unweighted image in the diffusion sequence is used as the reference image for motion and distortion correction. The remaining unweighted images are rigidly aligned to the reference image and averaged; this average image is used as the reference image for affine correction of the diffusion-weighted images (DWI) for motion and distortion caused by the diffusion weighting gradients. A brain mask is computed by aligning the average DWI to a template, and warping the template brain mask into the subject space. Processing then continues on the brain-extracted image. Diffusion tensors are calculated using an iterative weighted linear least squares algorithm \cite{Salvador2005HBM}.

Each T1-weighted image is segmented into gray matter, white matter and CSF using N4 bias correction \cite{tustison2010} and Atropos segmentation \cite{Avants2011a}. The white matter is used as a registration mask for alignment with the corresponding average DWI image. The DWI image is registered to the T1-weighted image using a transform composition derived by optimizing an initial rigid transformation followed by an optimized deformable (symmetric diffeomorphic using SyN \cite{Avants2011}) transform. The rigid transform is found by optimizing the alignment between the average DWI and the masked white matter T1-weighted image of the same subject, to account for motion. The resulting rigid transform is used to initialize distortion correction using the deformable transform.

The transformed DTI are warped to the template space by combining the intra-subject DWI to T1 warp with the warp previously defined to normalize the subject's T1 image to the template space. The correct anatomical orientation of the diffusion tensors is preserved by applying the preservation of principal direction method \cite{Alexander2001}, and scalar statistics such as FA and mean diffusivity are computed from the normalized diffusion tensors.


\subsubsection{Functional Image Processing}

Motion correction is performed for each time-series using
antsMotionCorr along with a sequcence specific reference image. In
the case of BOLD ..., for PASL the acquired M0 image is used as a
reference, while for PCASL and CASL ... A brain mask is computed by
aliging the image used as a reference for motion correction to a
template and warping the template brain mask into the subject
space. For ASL-based images, the difference between the tagged and
untagged BOLD signal at each time point is calculated using sinc subtraction \cite{Liu2005} and CBF is
then quantified using the appropriate acquisition parameters and the
methods of Wang, et al. \cite{Wang2003}. A mean CBF image is created by
averaging over the CBF time-signal. 

Graph construction. Cortical labels such as the Automated Anatomical
Labeling (AAL) atlas \cite{Tzourio-Mazoyer2002} are mapped from
the template space into the subject space via the same method used to
generate subject space brain masks described above. For each cortical
and subcortical label, a region-averaged time-signal is
calculated. Each time-series is then bandpass filtered using the
Christiano-Fitzgerald filtering \cite{Christiano2003}, as
implemented by the R function cffilter in package mFilter, to examine
a range of frequencies appropriate for the specific data type. An NxN
correlation matrix is then calculated by finding the correlation
between the filtered time-signals for each of the N labeled regions.

Graph analysis. To each correlation matrix, sparsity thresholds are
applied to binarize the edges, such that the bottom 50\% to 97.5\% of
the edges are discarded and the remaining edges set to a common
weight of 1.  This approach maintains graph density across subjects
and controls for inter-subject variation in base correlation levels
\cite{Liu2008, Power2011, Schwarz2011, Braun2012, Liang2012}. 
On the binarized graphs, are variety of network measures may be
computed including typically analyzed metrics such as: transitivity,
modularity, efficiency, clustering coefficient, characteristic path
length, and small-worldness. These metrics measure efficiency of
information transmission and community structure, and are calculated
with the R package brainwaver \cite{Achard2006}.

\subsubsection{BOLD rsfMRI Processing for Network Analysis}

Jeff --- from MICCAI Paper ?

\subsubsection{ASL Image Processing for CBF and Network Analysis}

Jeff --- from MICCAI Paper ?

\subsubsection{NIREP Data for Cortical Labelings}

The Nonrigid Image Registration Evaluation Project (NIREP)
\footnote{
http://www.nirep.org/
}) 
is an ongoing framework for evaluating image registration algorithms \citep{christensen2006}.
The initial data set introduced into the project consists of 
16 (8 male and 8 female) high resolution skull-stripped brain 
data with 32 cortical labels (cf. Table \ref{table:nirep_labels}) manually drawn using a 
published protocol.

Cortical label propagation to each individual subject for all data sets
described below is performed using the PICSL multi-atlas joint label fusion
algorithm described in \cite{wang2013} which recently topped the competition
at the MICCAI 2012 Grand Challenge on Multi-Atlas Labeling and is also 
distributed with the ANTs toolkit (program {\em jointfusion}).

%Given the gray matter labels, the white matter and CSF were identified 
%for each of the 16 subjects using Atropos.  Similar to the LPBA40
%data set, a NIREP template was created from all 16 subjects and each of the
%warped labels were used to create probabilistic estimates of the 
%labeled region boundaries. These probability maps were used as 
%spatial prior probabilities during the 3-tissue segmentation component
%of the pipeline.  Using SyN, the NIREP template is registered to the
%extracted individual subject brain which is followed by a warping of the 
%NIREP priors to the space of the individual subject.  The initial warped 
%white matter probability map is used as the weighted confidence mask 
%in the follow-up bias correction step.

\begin{table}
\centering
\begin{tabular*}{0.475\textwidth}{@{\extracolsep{\fill}} l l}
\toprule
  1) L occipital lobe & 2) R occipital lobe \\
  3) L cingulate gyrus & 4) R cingulate gyrus \\
  5) L insula gyrus & 6) R insula gyrus \\
  7) L temporal lobe & 8) R temporal lobe \\
  9) L superior temporal gyr. & 10) R superior temporal gyr. \\
  11) L infero temporal region & 12) R infero temporal region \\
  13) L parahippocampal gyr. & 14) R parahippocampal gyr. \\
  15) L frontal pole & 16) R frontal pole \\
  17) L superior frontal gyrus & 18) R superior frontal gyrus \\
  19) L middle frontal gyrus & 20) R middle frontal gyrus \\
  21) L inferior gyrus & 22) R inferior gyrus \\
  23) L orbital frontal gyrus & 24) R orbital frontal gyrus \\
  25) L precentral gyrus & 26) R precentral gyrus \\
  27) L superior parietal lobule & 28) R superior parietal lobule \\
  29) L inferior parietal lobule & 30) R inferior parietal lobule \\
  31) L postcentral gyrus & 32)   R postcentral gyrus \\  
\bottomrule
\end{tabular*}
\caption{The 32 cortical NIREP labels.}
\label{table:nirep_labels}
\end{table}


\begin{figure}
  \centering
  \includegraphics[width=90mm]{figs/template50_60.pdf}
  \caption{Sample multivariate template constructed from a subset of the IXI data (female, age 50--60).  Axial slices of five of the 37 total subjects from this cohort are shown. }
  \label{fig:template}
\end{figure}


